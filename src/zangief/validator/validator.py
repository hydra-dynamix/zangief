import os
import asyncio
import concurrent.futures
import re
import time
from functools import partial
import numpy as np
import random
import argparse
import asyncio
import logging
from typing import cast, Any, Dict, List

from communex.client import CommuneClient
from communex.module.client import ModuleClient
from communex._common import get_node_url
from communex.compat.key import classic_load_key
from communex.module.module import Module
from communex.types import Ss58Address
from communex.misc import get_map_modules

from substrateinterface import Keypair

from loguru import logger

from .weights_io import ensure_weights_file, write_weight_file, read_weight_file
from .power_scaling import conditional_power_scaling
from .reward import Reward
from .prompt_datasets.cc_100 import CC100

from zangief.config.validator import ValidatorConfig

logger.add("logs/log_{time:YYYY-MM-DD}.log", rotation="1 day", level="INFO")

IP_REGEX = re.compile(r"\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d+")


def extract_address(string: str):
    """
    Extracts an address from a string.
    """
    return re.search(IP_REGEX, string)


def get_miner_ip_port(client: CommuneClient, netuid: int, balances=False):
    modules = cast(dict[str, Any], get_map_modules(
        client, netuid=netuid, include_balances=balances))

    # Convert the values to a human readable format
    modules_to_list = [value for _, value in modules.items()]

    miners: list[Any] = []

    for module in modules_to_list:
        if module["incentive"] == module["dividends"] == 0:
            miners.append(module)
        elif module["incentive"] > module["dividends"]:
            miners.append(module)

    return miners


def get_ip_port(modules_adresses: dict[int, str]):
    """
    Get the IP and port information from module addresses.

    Args:
        modules_addresses: A dictionary mapping module IDs to their addresses.

    Returns:
        A dictionary mapping module IDs to their IP and port information.
    """

    filtered_addr = {id: extract_address(addr) for id, addr in modules_adresses.items()}
    ip_port = {
        id: x.group(0).split(":") if x is not None else ["0.0.0.0", "00"] for id, x in filtered_addr.items()
    }

    return ip_port


def get_netuid(is_testnet):
    if is_testnet:
        return 23
    else:
        return 13


def normalize_scores(scores):
    """Normalize scores to sum to 1.0"""
    if not scores:  # Handle empty sequence
        return []
    if all(s == 0 for s in scores):  # Handle all zeros
        return [1.0/len(scores)] * len(scores)
    total = sum(scores)
    if total == 0:  # Another check for zero sum
        return [1.0/len(scores)] * len(scores)
    return [s/total for s in scores]


def conditional_power_scaling(scores):
    """Apply power scaling to scores"""
    if not scores:  # Handle empty sequence
        return []
    if all(s == 0 for s in scores):  # Handle all zeros
        return [1.0/len(scores)] * len(scores)
    return scores  # For now, return scores as is, we can add power scaling later if needed


class TranslateValidator(Module):
    """
    A class for validating text generated by modules in a subnet.

    Attributes:
        client: The CommuneClient instance used to interact with the subnet.
        key: The keypair used for authentication.
        netuid: The unique identifier of the subnet.
        call_timeout: The timeout value for module calls in seconds (default: 60).

    Methods:
        get_modules: Retrieve all module addresses from the subnet.
        _get_miner_prediction: Prompt a miner module to generate an answer to the given question.
        _score_miner: Score the generated answer against the validator's own answer.
        get_miner_prompt: Generate a prompt for the miner modules.
        validate_step: Perform a validation step by generating questions, prompting modules, and scoring answers.
        validation_loop: Run the validation loop continuously based on the provided settings.
    """

    def __init__(
        self,
        key: Keypair,
        netuid: int,
        client: CommuneClient,
        call_timeout: int = 30,
        use_testnet: bool = False,
    ) -> None:
        super().__init__()
        self.client = client
        self.key = key
        self.netuid = netuid
        self.call_timeout = call_timeout
        self.use_testnet = use_testnet
        self.uid = None
        home_dir = os.path.expanduser("~")
        commune_dir = os.path.join(home_dir, ".commune")
        self.zangief_dir = os.path.join(commune_dir, "zangief")
        self.weights_file = os.path.join(self.zangief_dir, "weights.json")
        ensure_weights_file(zangief_dir_name=self.zangief_dir, weights_file_name=self.weights_file)
        write_weight_file(self.weights_file, {})
        self.keys_map = self.get_key(self.client, self.netuid)
        self.addresses_map = self.get_addresses(self.client, self.netuid)
        
        # Log the initial maps
        logger.info(f"Netuid: {self.netuid}")
        logger.info(f"Initial keys map size: {len(self.keys_map) if isinstance(self.keys_map, dict) else 'unknown'}")
        logger.info(f"Initial addresses map size: {len(self.addresses_map) if isinstance(self.addresses_map, dict) else 'unknown'}")
        logger.debug(f"Keys map: {self.keys_map}")
        logger.debug(f"Addresses map: {self.addresses_map}")
        
        self.miner_info_list = []
        self.reward = Reward()
        
        # Just load the list of available languages
        logger.info("Loading available languages...")
        self.cc_100 = CC100()
        self.languages = self.cc_100.selected_languages
        logger.info(f"Found {len(self.languages)} available languages")

    def load_languages(self):
        """
        Load languages and datasets once and store them in memory
        """
        try:
            # Load CC-100 dataset
            logger.info(f"Successfully loaded {len(self.languages)} languages")
        except Exception as e:
            logger.error(f"Error loading languages: {e}")
            raise

    def get_addresses(self, client: CommuneClient, netuid: int) -> dict[int, str]:
        """
        Retrieve all module addresses from the subnet.

        Args:
            client: The CommuneClient instance used to query the subnet.
            netuid: The unique identifier of the subnet.

        Returns:
            A dictionary mapping module IDs to their addresses.
        """
        try:
            return client.query_map_address(netuid)
        except Exception as e:
            logger.error(f"Error getting addresses: {str(e)}")
        return {}

    def get_key(self, client: CommuneClient, netuid: int) -> dict[int, str]:
        """
        Retrieve all module keys from the subnet.

        Args:
            client: The CommuneClient instance used to query the subnet.
            netuid: The unique identifier of the subnet.

        Returns:
            A dictionary mapping module IDs to their SS58 keys.
        """
        try:
            return client.query_map_key(netuid)
        except Exception as e:
            logger.error(f"Error getting keys: {str(e)}")
        return {}

    def split_ip_port(self, ip_port):
        # Check if the input is empty or None
        if not ip_port:
            return None, None

        # Split the input string by the colon
        parts = ip_port.split(":")

        # Check if the split resulted in exactly two parts
        if len(parts) == 2:
            ip, port = parts
            return ip, port
        else:
            return None, None

    async def _get_miner_prediction(
        self,
        miner_prompt: tuple,
        miner_info: dict,
    ) -> str | None:
        """
        Prompt a miner module to generate an answer to the given question.

        Args:
            question: The question to ask the miner module.
            miner_info: A tuple containing the miner's connection information and key.

        Returns:
            The generated answer from the miner module, or None if the miner fails to generate an answer.
        """
        question, source_language, target_language = miner_prompt
        miner_key = miner_info["key"]
        module_ip, module_port = miner_info["address"].split(":")

        client = ModuleClient(module_ip, int(module_port), self.key)

        try:
            miner_answer = await client.call(
                "generate",
                miner_key,
                {"prompt": question, "source_language": source_language, "target_language": target_language},
                timeout=self.call_timeout,
            )
            miner_answer = miner_answer["answer"]
            return miner_answer
        except Exception as e:
            logger.error(f"Error getting prediction from miner {miner_key}: {str(e)}")
            return ""

    async def _return_miner_scores(
        self,
        score: float,
        miner_info: dict,
    ):
        miner_key = miner_info["key"]
        module_ip, module_port = miner_info["address"].split(":")

        client = ModuleClient(module_ip, int(module_port), self.key)

        try:
            send_miner_score = await client.call(
                "score",
                miner_key,
                score,
                timeout=10
            )
            return send_miner_score['answer']
        except Exception as e:
            logger.error(f"Error returning score to miner {miner_key}: {str(e)}")
            return False

    def get_miners_to_query(self) -> List[Dict[str, Any]]:
        """Get list of miners to query."""
        try:
            # Clear previous miner info list
            self.miner_info_list = []
            
            # Get maps from class attributes
            query_map_key = self.keys_map
            query_map_address = self.addresses_map

            # Convert query results to dictionaries if they aren't already
            if not isinstance(query_map_key, dict):
                query_map_key = dict(query_map_key)
            if not isinstance(query_map_address, dict):
                query_map_address = dict(query_map_address)

            for uid, ss58key in query_map_key.items():
                address = query_map_address.get(uid)
                # Skip miners with invalid addresses
                if address in ["None:None", "0.0.0.0:8080"]:
                    logger.debug(f"Skipping miner with invalid address - UID: {uid}, Key: {ss58key}, Address: {address}")
                    continue
                    
                miner_info = {
                    "uid": uid,
                    "address": address,
                    "key": ss58key,
                }
                self.miner_info_list.append(miner_info)

            logger.info(f"Found {len(self.miner_info_list)} valid miners to query")
            logger.debug(f"First few miners for debugging: {self.miner_info_list[:5] if self.miner_info_list else []}")
            
            return self.miner_info_list

        except Exception as e:
            logger.error(f"Error getting miners to query: {str(e)}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            # Don't clear the miner list on error, return what we have
            return self.miner_info_list

    async def run(self):
        """Run the validator."""
        try:
            # Get validator UID using stored keys map
            val_ss58 = self.key.ss58_address
            for uid, ss58 in enumerate(self.keys_map):
                if ss58.__str__() == val_ss58:
                    self.uid = uid
                    break

            miners_to_query = self.get_miners_to_query()
            
            logger.info(f"Got {len(miners_to_query)} miners to query")
            logger.debug(f"Miner addresses: {[m['address'] for m in miners_to_query]}")
            
            if not miners_to_query:
                logger.warning("No miners to query")
                return

            miner_prompt = self.get_miner_prompt()

            logger.debug("Source")
            logger.debug(miner_prompt[1])
            logger.debug("Target")
            logger.debug(miner_prompt[2])
            logger.debug("Prompt")
            logger.debug(miner_prompt[0])

            # Get predictions from all miners concurrently
            logger.debug("Getting predictions from miners...")
            miner_answers = await asyncio.gather(
                *[self._get_miner_prediction(miner_prompt, miner) for miner in miners_to_query],
                return_exceptions=True
            )

            # Filter out exceptions and failed responses
            valid_answers = []
            valid_miners = []
            for miner, answer in zip(miners_to_query, miner_answers):
                if isinstance(answer, Exception):
                    logger.error(f"Error from miner {miner['key']}: {str(answer)}")
                    continue
                if not answer:  # Empty string response
                    logger.warning(f"Empty response from miner {miner['key']}")
                    continue
                valid_answers.append(answer)
                valid_miners.append(miner)

            if not valid_answers:
                logger.warning("No valid responses from miners")
                return

            scores, full_scores = self.reward.get_scores(miner_prompt[0], miner_prompt[2], valid_answers)

            # Return scores to miners concurrently
            logger.debug("Returning scores to miners...")
            await asyncio.gather(
                *[self._return_miner_scores(score, miner) for score, miner in zip(full_scores, valid_miners)],
                return_exceptions=True
            )

            logger.debug("Miner prompt")
            logger.debug(miner_prompt)
            logger.debug("Valid miner answers")
            logger.debug(valid_answers)
            logger.debug("Raw scores")
            logger.debug(scores)

            # Create score dictionary using valid miners only
            score_dict: dict[int, float] = {}
            for miner, score in zip(valid_miners, scores):
                uid = int(miner['uid'])  # Use the original UID from miner info
                score_dict[uid] = score
                logger.debug(f"Scoring miner {uid} with score {score}")

            data_to_write = {}
            logger.info(f"SCORE DICT: {score_dict}")
            for miner in valid_miners:  # Use valid_miners here too
                uid = int(miner['uid'])
                ss58 = miner['key']
                score = score_dict[uid]
                data_to_write[uid] = {"ss58": ss58, "score": score}

            current_weights = read_weight_file(self.weights_file)
            for key, data in data_to_write.items():
                current_weights[key] = data

            write_weight_file(self.weights_file, current_weights)
            ddd = read_weight_file(self.weights_file)
            logger.info(f"READ DATA: {ddd}")

            logger.info("Miner UIDs")
            logger.info([m['uid'] for m in valid_miners])
            logger.info("Final scores")
            logger.info(scores)

            if len(valid_miners) == 0:
                scores = read_weight_file(self.weights_file)

                s_dict: dict[int: float] = {}
                for uid, data in scores.items():
                    s_dict[uid] = data['score']

                logger.info("SETTING WEIGHTS")
                self.set_weights(s_dict)
                write_weight_file(self.weights_file, {})
                self.load_languages()

        except Exception as e:
            logger.error(f"Error running validator: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")

    def get_miner_prompt(self) -> tuple:
        """
        Generate a prompt for the miner modules by getting a single random sample
        """
        # Select random source and target languages
        source_language = np.random.choice(self.languages).item()
        target_language = np.random.choice([lang for lang in self.languages if lang != source_language]).item()
        
        # Get a single random record from the source language
        source_text = self.cc_100.get_random_record(source_language)
        
        # Create the prompt tuple
        prompt = (source_text, source_language, target_language)
        
        logger.debug(f"Generated prompt: {source_language} -> {target_language}")
        return prompt

    def validate_step(
        self, netuid: int
    ) -> None:
        """
        Perform a validation step.

        Generates questions based on the provided settings, prompts modules to generate answers,
        and scores the generated answers against the validator's own answers.

        Args:
            netuid: The network UID of the subnet.
        """

        miners = get_miner_ip_port(self.client, self.netuid)

        modules_keys = self.client.query_map_key(netuid)
        val_ss58 = self.key.ss58_address
        if val_ss58 not in modules_keys.values():
            logger.error(f"Validator key {val_ss58} is not registered in subnet")
            return None

        for uid, ss58 in modules_keys.items():
            if ss58.__str__() == val_ss58:
                self.uid = uid

        miners_to_query = self.get_miners_to_query()

        miner_prompt = self.get_miner_prompt()

        logger.debug("Source")
        logger.debug(miner_prompt[1])
        logger.debug("Target")
        logger.debug(miner_prompt[2])
        logger.debug("Prompt")
        logger.debug(miner_prompt[0])

        logger.debug("Creating miner prediction partial...")
        get_miner_prediction = partial(self._get_miner_prediction, miner_prompt)

        logger.debug("Prompting miners...")
        with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
            it = executor.map(get_miner_prediction, miners_to_query)
            miner_answers = [*it]

        scores, full_scores = self.reward.get_scores(miner_prompt[0], miner_prompt[2], miner_answers)

        for i, full_score in enumerate(full_scores):
            send_miner_score = partial(self._return_miner_scores, full_score)

            with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
                rs = executor.map(send_miner_score, [miners_to_query[i]])
                successes = [*rs]

        logger.debug("Miner prompt")
        logger.debug(miner_prompt)
        logger.debug("Miner answers")
        logger.debug(miner_answers)
        logger.debug("Raw scores")
        logger.debug(scores)

        # Create score dictionary using valid miners only, maintaining order
        score_dict: dict[int, float] = {}
        data_to_write = {}
        
        # Process miners and scores together to maintain order
        for idx, (miner, score) in enumerate(zip(valid_miners, scores)):
            uid = int(miner['uid'])
            ss58 = miner['key']
            score_dict[uid] = score
            data_to_write[uid] = {"ss58": ss58, "score": score}
            logger.debug(f"Processing miner {idx}: UID {uid}, Key {ss58}, Score {score}")
        
        logger.info(f"SCORE DICT: {score_dict}")
        
        # Update weights file in one operation
        current_weights = read_weight_file(self.weights_file)
        current_weights.update(data_to_write)
        write_weight_file(self.weights_file, current_weights)
        
        ddd = read_weight_file(self.weights_file)
        logger.info(f"READ DATA: {ddd}")
        
        # Log UIDs and scores in guaranteed matching order
        miner_uids = [int(m['uid']) for m in valid_miners]
        logger.info("Miner UIDs")
        logger.info(miner_uids)
        logger.info("Final scores")
        logger.info(scores)
        if len(miners_to_query) == 0:
            scores = read_weight_file(self.weights_file)

            s_dict: dict[int: float] = {}
            for uid, data in scores.items():
                s_dict[uid] = data['score']

            logger.info("SETTING WEIGHTS")
            self.set_weights(s_dict)
            write_weight_file(self.weights_file, {})
            self.load_languages()

    def validation_loop(self, config) -> None:
        while True:
            logger.info("Begin validator step ... ")
            asyncio.run(self.run())
            interval = config.get_validator_interval()
            logger.info(f"Sleeping for {interval} seconds ... ")
            time.sleep(interval)

    def set_weights(self, s_dict):
        """
        Set weights for miners based on their normalized and power scaled scores.
        """
        while True:
            try:
                # Convert scores to list format for normalization
                uids = list(s_dict.keys())
                scores = list(s_dict.values())
                
                if not scores:  # If we have no scores, skip setting weights
                    logger.warning("No scores available, skipping weight setting")
                    return
                
                logger.info(f"Setting weights for {len(scores)} miners")
                logger.info(f"Raw scores: {scores}")

                # Check if all scores are zero
                if all(s == 0 for s in scores):
                    logger.warning("All scores are zero, setting equal weights")
                    normalized_weights = [1.0/len(scores)] * len(scores)
                else:
                    # Normalize weights
                    normalized_weights = normalize_scores(scores)
                
                logger.info(f"Normalized weights: {normalized_weights}")

                # Power scale weights
                power_scaled_weights = conditional_power_scaling(normalized_weights)
                logger.info(f"Power scaled weights: {power_scaled_weights}")

                # Convert to integer weights for the chain
                values = [int(w * 65535) for w in power_scaled_weights]
                
                # Convert UIDs from strings to integers
                uids = [int(uid) for uid in uids]

                logger.info(f"Setting weights for UIDs: {uids}")
                logger.info(f"Setting values: {values}")

                self.client.set_weights(self.netuid, uids, values, key=self.key)
                break  # If successful, break out of the retry loop
            except Exception as e:
                if hasattr(e, 'code') and e.code == 1014:
                    logger.warning("Transaction priority too low, waiting 5 seconds before retry...")
                    time.sleep(5)
                    continue
                else:
                    logger.error(f"Error setting weights: {e}")
                    raise


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="zangief validator")
    parser.add_argument("--env", type=str, default=".env", help="config file path")
    parser.add_argument('--ignore-env-file', action='store_true', help='If set, ignore .env file')
    args = parser.parse_args()

    logger.info("Loading validator config ... ")

    # Load config, and get the values.
    validator_config = ValidatorConfig(env_path=args.env, ignore_config_file=args.ignore_env_file)

    testnet = validator_config.get_testnet()
    keyname = validator_config.get_key_name()
    netuid = validator_config.get_netuid()
    call_timeout = validator_config.get_validator_call_timeout()
    interval = validator_config.get_validator_interval()
    key_password = validator_config.get_key_password()

    if key_password is not None:
        key = classic_load_key(keyname, password=key_password)
    else:
        key = classic_load_key(keyname)

    if testnet:
        logger.info("Connecting to TEST network ... ")
    else:
        logger.info("Connecting to Main network ... ")

    validator = TranslateValidator(
        key=key,
        netuid=netuid,
        client=CommuneClient(get_node_url(use_testnet=testnet)),
        call_timeout=call_timeout,
        use_testnet=testnet
    )

    logger.info("Running validator ... ")
    validator.validation_loop(validator_config)
